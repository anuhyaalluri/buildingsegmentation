{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anuhy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\anuhy\\Desktop\\NRSC\\model.py:104: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "import time\n",
    "import tifffile as tiff\n",
    "from loader import Loader\n",
    "import model as m\n",
    "from scipy import ndimage, misc\n",
    "from random import shuffle, randint\n",
    "\n",
    "input_files = [f for f in listdir('input_data')]\n",
    "shuffle(input_files)\n",
    "train_files = input_files[5:]\n",
    "validation_files = input_files[:5]\n",
    "\n",
    "\n",
    "\n",
    "def processor1(fn, config):\n",
    "  input_image = tiff.imread('input_data/{0}'.format(fn))\n",
    "  label_image = tiff.imread('label_data/{0}'.format(fn[:-1]))\n",
    "  label_image = label_image[:, :, :1] / 255\n",
    "\n",
    "  if config.augment:\n",
    "    angle = randint(0, 360)\n",
    "    input_image = ndimage.rotate(input_image, angle, reshape=False)\n",
    "    label_image = ndimage.rotate(label_image, angle, reshape=False)\n",
    "\n",
    "  input_image = (input_image - np.mean(input_image)) / np.std(input_image)\n",
    "  return (fn, input_image, label_image)\n",
    "\n",
    "\n",
    "\n",
    "validation_loader = Loader(validation_files, 5, processor=processor1)\n",
    "validation_loader.start()\n",
    "validation_loader.stop()\n",
    "validation_batch = validation_loader.get_batch(5)\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "train_files= input_files[5:]\n",
    "train_loader = Loader(train_files, batch_size * 4, processor=processor1, randomize=True, augment=True)\n",
    "train_loader.start()\n",
    "\n",
    "\n",
    "shouldLoad = True\n",
    "modelName = m.modelName \n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "config.log_device_placement = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "  saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)\n",
    "  summary_writer = tf.summary.FileWriter('summary/{0}'.format(modelName), graph=sess.graph)\n",
    "  summary_writer_validation = tf.summary.FileWriter('summary/{0}-validation'.format(modelName), graph=sess.graph)\n",
    "\n",
    "  if shouldLoad:\n",
    "    saver.restore(sess, modelName)\n",
    "  else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  startTime = time.time()\n",
    "  print(\"{0}: training start;\".format(startTime))\n",
    "\n",
    "  while True:\n",
    "    batch = train_loader.get_batch(batch_size)\n",
    "    filenames = batch[0]\n",
    "    input_images = batch[1]\n",
    "    label_images = batch[2]\n",
    "\n",
    "    _, error, summary, step = sess.run([m.train, m.error, m.summary, m.global_step], feed_dict={ \n",
    "      m.input_image: input_images,  \n",
    "      m.label_image: label_images\n",
    "    })\n",
    "\n",
    "    #if step % 20 == 0:\n",
    "    #   save_path = saver.save(sess, modelName)\n",
    "    summary_writer.add_summary(summary, step)\n",
    "    #print(time.time() - startTime, step, error)\n",
    "    if step % (100 / batch_size) == 0:\n",
    "      filenames = validation_batch[0]\n",
    "      input_images = validation_batch[1]\n",
    "      label_images = validation_batch[2]\n",
    "\n",
    "      error, learning_rate, result = sess.run([m.error, m.learning_rate, m.result], feed_dict={ \n",
    "        m.input_image: input_images,  \n",
    "        m.label_image: label_images,\n",
    "        m.is_train: False\n",
    "      })\n",
    "\n",
    "      summary_writer_test.add_summary(summary, step)\n",
    "\n",
    "      print(\"time={0}: step={1};  error={2};  lrate={3};\".format(time.time() - startTime, step, error, learning_rate))\n",
    "\n",
    "      filename = filenames[0]\n",
    "      result_image = result[0].reshape((1500, 1500))\n",
    "      misc.imsave(\"results/{0}-{1}-{2}.png\".format(modelName, filename, step), result_image)\n",
    "\n",
    "    \n",
    "\n",
    "    if step == 500: \n",
    "        saver.save(sess, 'my_test_model',global_step=500)\n",
    "        break\n",
    "\n",
    "train_loader.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_saver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-217c2e995240>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m#graph = tf.get_default_graph()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m#new_saver = tf.train.import_meta_graph('my_test_model-500.meta')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mnew_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_saver' is not defined"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from random import shuffle, randint\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tifffile as tiff\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "from loader import Loader\n",
    "import model as m\n",
    "\n",
    "#label_files = [filename for filename in listdir('input_images')]\n",
    "#label_files.sort()\n",
    "#shuffle(label_files)\n",
    "\n",
    "\n",
    "def data_processor2(filename, config):\n",
    "  input_image = tiff.imread('test_images/{0}'.format(filename))\n",
    "\n",
    "  if config.augment:\n",
    "    angle = randint(0, 360)\n",
    "    label_image = ndimage.rotate(label_image, angle, reshape=False)\n",
    "\n",
    "  input_image = (input_image - np.mean(input_image)) / np.std(input_image)\n",
    "  return (filename, input_image)\n",
    "\n",
    "test_files = [filename for filename in listdir('test_images')]\n",
    "test_loader = Loader(test_files, 1, processor=data_processor2)\n",
    "test_loader.start()\n",
    "test_batch = test_loader.get_batch(1)\n",
    "test_loader.stop()\n",
    "\n",
    "batch_size=2\n",
    "\n",
    "shouldLoad = True\n",
    "modelName = m.modelName + \"-x2-msr\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "config.log_device_placement = True\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #graph = tf.get_default_graph()\n",
    "    new_saver = tf.train.import_meta_graph('my_test_model-500.meta') \n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "    graph = tf.get_default_graph() \n",
    "\n",
    "    startTime = time.time()\n",
    "    #print(\"{0}: testing start;\".format(startTime))\n",
    "\n",
    "  \n",
    "    #print(time.time() - startTime, step, error)\n",
    "    filenames = test_batch[0]\n",
    "    input_images = test_batch[1]\n",
    "    result= sess.run([m.result], feed_dict={ \n",
    "        m.input_image: input_images,  \n",
    "        m.is_train: False\n",
    "      })\n",
    "\n",
    "    \n",
    "    result_image = result[0].reshape((1500, 1500))\n",
    "    misc.imsave(\"test_results/result.png\", result_image)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

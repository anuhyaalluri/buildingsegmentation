{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559652835.0993688: training start;\n",
      "4473.935047149658: step 50; train 0.22849328815937042; test 0.3790343701839447; lrate 0.10000000149011612;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anuhy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:97: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999.106883764267: step 100; train 0.1842738837003708; test 0.4261179566383362; lrate 0.10000000149011612;\n",
      "13432.507910490036: step 150; train 0.1560789942741394; test 0.28968310356140137; lrate 0.10000000149011612;\n",
      "17875.124626874924: step 200; train 0.13615931570529938; test 0.30584654211997986; lrate 0.10000000149011612;\n",
      "22369.890480279922: step 250; train 0.13196459412574768; test 0.2716556787490845; lrate 0.10000000149011612;\n",
      "26870.695236444473: step 300; train 0.12725360691547394; test 0.22050590813159943; lrate 0.10000000149011612;\n",
      "31340.322456121445: step 350; train 0.12848080694675446; test 0.20801280438899994; lrate 0.10000000149011612;\n",
      "35702.350910425186: step 400; train 0.11230155825614929; test 0.21322666108608246; lrate 0.10000000149011612;\n",
      "40012.44082379341: step 450; train 0.11761485785245895; test 0.3089674413204193; lrate 0.10000000149011612;\n",
      "44353.38786697388: step 500; train 0.10624142736196518; test 0.21733519434928894; lrate 0.10000000149011612;\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from random import shuffle, randint\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tifffile as tiff\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "from loader import Loader\n",
    "import model as m\n",
    "\n",
    "\n",
    "input_files = [f for f in listdir('input_data')]\n",
    "shuffle(input_files)\n",
    "\n",
    "\n",
    "def data_processor(f, config):\n",
    "  input_image = tiff.imread('input_data/{0}'.format(f))\n",
    "  label_image = tiff.imread('label_data/{0}'.format(f[:-1]))\n",
    "  label_image = label_image[:, :, :1] / 255\n",
    "\n",
    "  if config.augment:\n",
    "    angle = randint(0, 360)\n",
    "    input_image = ndimage.rotate(input_image, angle, reshape=False)\n",
    "    label_image = ndimage.rotate(label_image, angle, reshape=False)\n",
    "\n",
    "  input_image = (input_image - np.mean(input_image)) / np.std(input_image)\n",
    "  return (f, input_image, label_image)\n",
    "\n",
    "\n",
    "validation_files = input_files[:5]\n",
    "validation_loader = Loader(validation_files, 5, processor=data_processor)\n",
    "validation_loader.start()\n",
    "validation_batch = validation_loader.get_batch(5)\n",
    "validation_loader.stop()\n",
    "\n",
    "batch_size = 2\n",
    "train_files = input_files[5:]\n",
    "train_loader = Loader(train_files, batch_size * 4, processor=data_processor, randomize=True, augment=True)\n",
    "train_loader.start()\n",
    "\n",
    "\n",
    "shouldLoad = False\n",
    "modelName = m.modelName \n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "config.log_device_placement = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "  saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)\n",
    "  summary_writer = tf.summary.FileWriter('summary/{0}'.format(modelName), graph=sess.graph)\n",
    "  summary_writer_test = tf.summary.FileWriter('summary/{0}-test'.format(modelName), graph=sess.graph)\n",
    "\n",
    "  if shouldLoad:\n",
    "    saver.restore(sess, modelName)\n",
    "  else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  startTime = time.time()\n",
    "  print(\"{0}: training start;\".format(startTime))\n",
    "\n",
    "  while True:\n",
    "    batch = train_loader.get_batch(batch_size)\n",
    "    filenames = batch[0]\n",
    "    input_images = batch[1]\n",
    "    label_images = batch[2]\n",
    "\n",
    "    _, error, summary, step = sess.run([m.train, m.error, m.summary, m.global_step], feed_dict={ \n",
    "      m.input_image: input_images,  \n",
    "      m.label_image: label_images\n",
    "    })\n",
    "\n",
    "    #if step % 20 == 0:\n",
    "    #   save_path = saver.save(sess, modelName)\n",
    "    summary_writer.add_summary(summary, step)\n",
    "    #print(time.time() - startTime, step, error)\n",
    "    if step % (100 / batch_size) == 0:\n",
    "      filenames = validation_batch[0]\n",
    "      input_images = validation_batch[1]\n",
    "      label_images = validation_batch[2]\n",
    "\n",
    "      validation_error, learning_rate, result, summary = sess.run([m.error, m.learning_rate, m.result, m.test_summary], feed_dict={ \n",
    "        m.input_image: input_images,  \n",
    "        m.label_image: label_images,\n",
    "        m.is_train: False\n",
    "      })\n",
    "\n",
    "      summary_writer_test.add_summary(summary, step)\n",
    "\n",
    "      print(\"{0}: step {1}; train {2}; test {3}; lrate {4};\".format(time.time() - startTime, step, error, validation_error, learning_rate))\n",
    "\n",
    "      filename = filenames[0]\n",
    "      result_image = result[0].reshape((1500, 1500))\n",
    "      misc.imsave(\"test_results/{0}-{1}-{2}.png\".format(modelName, filename, step), result_image)`\n",
    "\n",
    "    if step%100==0: \n",
    "    \n",
    "        saver.save(sess, 'my_test_model',global_step=step)\n",
    "\n",
    "    if step == 500: break\n",
    "\n",
    "train_loader.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_test_model-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anuhy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from random import shuffle, randint\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tifffile as tiff\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "from loader import Loader\n",
    "import model as m\n",
    "\n",
    "\n",
    "\n",
    "def data_processor2(f, config):\n",
    "  input_image = tiff.imread('test_images/{0}'.format(f))\n",
    "\n",
    "  if config.augment:\n",
    "    angle = randint(0, 360)\n",
    "    label_image = ndimage.rotate(label_image, angle, reshape=False)\n",
    "\n",
    "  input_image = (input_image - np.mean(input_image)) / np.std(input_image)\n",
    "  return (f, input_image)\n",
    "\n",
    "test_files = [filename for filename in listdir('test_images')]\n",
    "test_loader = Loader(test_files, 1, processor=data_processor2)\n",
    "test_loader.start()\n",
    "test_batch = test_loader.get_batch(1)\n",
    "test_loader.stop()\n",
    "\n",
    "batch_size=2\n",
    "\n",
    "shouldLoad = True\n",
    "modelName = m.modelName\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "config.log_device_placement = True\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #graph = tf.get_default_graph()\n",
    "    new_saver = tf.train.import_meta_graph('my_test_model-500.meta') \n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "    graph = tf.get_default_graph() \n",
    "\n",
    "    startTime = time.time()\n",
    "    #print(\"{0}: testing start;\".format(startTime))\n",
    "\n",
    "  \n",
    "    #print(time.time() - startTime, step, error)\n",
    "    filenames = test_batch[0]\n",
    "    input_images = test_batch[1]\n",
    "    result= sess.run([m.result], feed_dict={ \n",
    "        m.input_image: input_images,  \n",
    "        m.is_train: False\n",
    "      })\n",
    "\n",
    "    \n",
    "    result_image = result[0].reshape((1500, 1500))\n",
    "    misc.imsave(\"test_results/result.png\", result_image)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
